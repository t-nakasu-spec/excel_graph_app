# app.py
# --------------------------------------------
# Excelã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ æ¡ä»¶ã‚·ãƒ¼ãƒˆã®åˆ—ä½ç½®ã«åŸºã¥ãå›³ç•ªã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚° â†’ æ—¥/é€±/æœˆé›†è¨ˆ â†’ å¤šè»¸ã‚°ãƒ©ãƒ•ï¼ˆStreamlitï¼‰
# ä»•æ§˜è¦ç‚¹ï¼š
# - æ—¥ä»˜åˆ—ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã€ŒçŠ¶æ…‹ã€
# - æ¡ä»¶ã‚·ãƒ¼ãƒˆï¼šBåˆ—=å‡ºè·å“ç•ªã€Cåˆ—ä»¥é™=ã™ã¹ã¦ã‚°ãƒ©ãƒ•ç•ªå·ï¼ˆåˆ—åã¯ä½•ã§ã‚‚OKï¼‰
# - å·¦è»¸ï¼ˆæ£’ï¼‰ï¼šç”Ÿç”£æ¸ˆãƒ»ç”Ÿç”£æ™‚é–“[åˆ†]ã€å³è»¸ï¼ˆç·šï¼‰ï¼šå·¥æ•°
# - ç•°å¸¸å€¤ãƒ•ã‚£ãƒ«ã‚¿ã€ç²’åº¦ï¼ˆæ—¥/é€±/æœˆï¼‰ã€æœŸé–“æŒ‡å®šã€ç§»å‹•å¹³å‡ã€CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# --------------------------------------------

import numpy as np
import pandas as pd
import streamlit as st
import altair as alt

st.set_page_config(page_title="Excelã‚°ãƒ©ãƒ•åŒ–ãƒ„ãƒ¼ãƒ«ï¼ˆæ¡ä»¶ã‚·ãƒ¼ãƒˆå¯¾å¿œï¼‰", layout="wide")
st.title("ğŸ“Š Excelã‚°ãƒ©ãƒ•åŒ–ãƒ„ãƒ¼ãƒ«ï¼ˆæ¡ä»¶ã‚·ãƒ¼ãƒˆå¯¾å¿œï¼‰")

st.markdown(
    "- **ç·é›†è¨ˆï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿åˆç®—ï¼‰** â†’ **å„ã‚°ãƒ©ãƒ•åï¼ˆæ¡ä»¶ã‚·ãƒ¼ãƒˆ Cåˆ—ä»¥é™ï¼‰ã”ã¨**ã«è©²å½“ã€Œå‡ºè·å“ç•ªã€ã‚’**åˆç®—ã—ã¦**è¡¨ç¤º  \n"
    "- å·¦è»¸ï¼ˆæ£’ï¼‰: **ç”Ÿç”£æ¸ˆ**ãƒ»**ç”Ÿç”£æ™‚é–“[åˆ†]** ï¼ å³è»¸ï¼ˆç·šï¼‰: **å·¥æ•°**  \n"
    "- æ¡ä»¶ã‚·ãƒ¼ãƒˆã¯ **Båˆ—=å‡ºè·å“ç•ª**ã€**Cåˆ—ä»¥é™=ã‚°ãƒ©ãƒ•ç•ªå·ï¼ˆåˆ—åã¯ä»»æ„ï¼‰** ã¨ã—ã¦è‡ªå‹•è§£é‡ˆã—ã¾ã™"
)

# -----------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# -----------------------------
DATE_CANDIDATES = ["çŠ¶æ…‹", "ç”Ÿç”£æ—¥", "å‡ºè·æ—¥", "æ›´æ–°æ—¥æ™‚"]

def parse_datetime_series(s: pd.Series) -> pd.Series:
    """æ—¥ä»˜/æ—¥æ™‚ã£ã½ã„åˆ—ã‚’datetimeã¸ã€‚Excelã‚·ãƒªã‚¢ãƒ«/æ–‡å­—åˆ—/NaTã«å¯¾å¿œã€‚"""
    if s is None:
        return pd.Series([], dtype="datetime64[ns]")
    if np.issubdtype(s.dtype, np.datetime64):
        try:
            return s.dt.tz_localize(None)
        except Exception:
            return s
    # æ•°å€¤ï¼ˆExcelæ—¥æ•°ã‚·ãƒªã‚¢ãƒ«å¯¾å¿œï¼‰
    if np.issubdtype(s.dtype, np.number):
        try:
            return pd.to_datetime(s, unit="D", origin="1899-12-30", errors="coerce")
        except Exception:
            pass
    # æ–‡å­—åˆ—ãªã©
    return pd.to_datetime(s, errors="coerce", infer_datetime_format=True)

def ensure_numeric(s: pd.Series, fill=0) -> pd.Series:
    return pd.to_numeric(s, errors="coerce").fillna(fill)

def compute_minutes(soyo_time: pd.Series, mode: str) -> pd.Series:
    x = ensure_numeric(soyo_time, fill=0)
    return x * 1440.0 if mode == "excel_time" else x

def pick_default_date_col(df: pd.DataFrame) -> str:
    if "çŠ¶æ…‹" in df.columns:
        return "çŠ¶æ…‹"
    for c in DATE_CANDIDATES:
        if c in df.columns:
            return c
    for c in df.columns:
        if np.issubdtype(df[c].dtype, np.datetime64):
            return c
    return df.columns[0] if len(df.columns) else "æ—¥ä»˜"

def normalize_conditions_by_position(cond_raw: pd.DataFrame):
    """
    æ¡ä»¶ã‚·ãƒ¼ãƒˆã‚’åˆ—ä½ç½®ã§æ­£è¦åŒ–ï¼š
      - å‡ºè·å“ç•ª: ç‰©ç†Båˆ—ï¼ˆindex=1ï¼‰
      - ã‚°ãƒ©ãƒ•ç•ªå·: ç‰©ç†Cåˆ—ï¼ˆindex=2ï¼‰ä»¥é™ã‚’ã™ã¹ã¦å¯¾è±¡
    æˆ»ã‚Šå€¤: (æ­£è¦åŒ–DataFrame, ã‚°ãƒ©ãƒ•åˆ—åãƒªã‚¹ãƒˆ)
    """
    if cond_raw is None or cond_raw.empty:
        return pd.DataFrame(columns=["å‡ºè·å“ç•ª"]), []

    cond = cond_raw.copy()
    cols = list(cond.columns)

    # Båˆ— â†’ å‡ºè·å“ç•ª
    if len(cols) >= 2:
        cond.rename(columns={cols[1]: "å‡ºè·å“ç•ª"}, inplace=True)
    else:
        cond["å‡ºè·å“ç•ª"] = np.nan  # è¶³ã‚Šãªã„å ´åˆã¯ç©ºåˆ—

    # Cä»¥é™ â†’ ã™ã¹ã¦ã‚°ãƒ©ãƒ•åˆ—ã¨ã—ã¦æ‰±ã†ï¼ˆåˆ—åã¯ä½•ã§ã‚‚å¯ï¼‰
    graph_cols = []
    if len(cols) >= 3:
        graph_cols = cols[2:]  # 2ç•ªç›®ä»¥é™å…¨ã¦
        # å…¨éƒ¨ç©ºã®åˆ—ã¯é™¤å¤–
        keep = []
        for c in graph_cols:
            series = cond[c]
            if series.notna().any() and series.astype(str).str.strip().replace("nan", "").ne("").any():
                keep.append(c)
        graph_cols = keep

    # æœ€ä½é™ã®åˆ—ã ã‘æ®‹ã™
    keep_show = ["å‡ºè·å“ç•ª"] + graph_cols
    cond = cond[[c for c in keep_show if c in cond.columns]].copy()

    # å‡ºè·å“ç•ª æ­£è¦åŒ–
    if "å‡ºè·å“ç•ª" in cond.columns:
        cond["å‡ºè·å“ç•ª"] = cond["å‡ºè·å“ç•ª"].astype(str).str.strip()

    return cond, graph_cols

def build_graph_map_dynamic(cond: pd.DataFrame, graph_cols: list[str]) -> dict:
    """
    ã‚°ãƒ©ãƒ•åï¼ˆã‚»ãƒ«å€¤ï¼‰â†’ {å‡ºè·å“ç•ª,...} ã®è¾æ›¸ã‚’ç”Ÿæˆã€‚
    graph_cols ã®å„åˆ—ã«æ›¸ã‹ã‚ŒãŸã‚»ãƒ«ã®å€¤ã‚’â€œã‚°ãƒ©ãƒ•åâ€ã¨ã—ã¦æ‰±ã†ã€‚
    """
    mapping: dict[str, set] = {}
    if "å‡ºè·å“ç•ª" not in cond.columns or not graph_cols:
        return mapping

    for _, row in cond.iterrows():
        item = str(row["å‡ºè·å“ç•ª"]).strip()
        if not item or item.lower() == "nan":
            continue
        for c in graph_cols:
            g = row.get(c, None)
            if pd.isna(g):
                continue
            gname = str(g).strip()
            if gname == "" or gname.lower() == "nan":
                continue
            mapping.setdefault(gname, set()).add(item)
    return mapping

def aggregate_timeseries(df: pd.DataFrame, date_col: str, freq: str, ma_window: int | None) -> pd.DataFrame:
    """
    æ—¥ä»˜åˆ—ã§é›†è¨ˆï¼ˆfreq='D'|'W'|'M'ï¼‰ã€‚å·¥æ•°=ç”Ÿç”£æ™‚é–“[åˆ†]/ç”Ÿç”£æ¸ˆï¼ˆ0é™¤ç®—=0ï¼‰ã€‚
    """
    _df = df.copy()
    _df[date_col] = parse_datetime_series(_df[date_col])
    _df = _df.dropna(subset=[date_col])

    _df["ç”Ÿç”£æ¸ˆ"] = ensure_numeric(_df.get("ç”Ÿç”£æ¸ˆ", pd.Series(dtype=float)), 0)
    _df["ç”Ÿç”£æ™‚é–“[åˆ†]"] = ensure_numeric(_df.get("ç”Ÿç”£æ™‚é–“[åˆ†]", pd.Series(dtype=float)), 0)

    _df = _df.set_index(date_col).sort_index()
    grouped = _df.resample(freq).agg({"ç”Ÿç”£æ¸ˆ": "sum", "ç”Ÿç”£æ™‚é–“[åˆ†]": "sum"})
    grouped["å·¥æ•°"] = np.where(grouped["ç”Ÿç”£æ¸ˆ"] > 0, grouped["ç”Ÿç”£æ™‚é–“[åˆ†]"] / grouped["ç”Ÿç”£æ¸ˆ"], 0.0)

    if ma_window and ma_window > 1:
        grouped["å·¥æ•°_MA"] = grouped["å·¥æ•°"].rolling(ma_window, min_periods=1).mean()
    else:
        grouped["å·¥æ•°_MA"] = np.nan

    grouped = grouped.reset_index().rename(columns={date_col: "æ—¥ä»˜"})
    # æ—¥ä»˜åˆ—ã‚’ç¢ºå®Ÿã«datetimeå‹ã«ä¿æŒ
    if "æ—¥ä»˜" in grouped.columns:
        grouped["æ—¥ä»˜"] = pd.to_datetime(grouped["æ—¥ä»˜"])
    return grouped

def alt_dual_axis_chart(agg_df: pd.DataFrame, title: str):
    """
    å·¦è»¸ï¼šæ£’ï¼ˆç”Ÿç”£æ¸ˆãƒ»ç”Ÿç”£æ™‚é–“[åˆ†]ï¼‰/ å³è»¸ï¼šç·šï¼ˆå·¥æ•° or MAï¼‰
    """
    if agg_df.empty:
        return alt.Chart(pd.DataFrame({"x": [], "y": []})).mark_text(text="ãƒ‡ãƒ¼ã‚¿ãªã—")
    
    # æ—¥ä»˜åˆ—ã‚’ç¢ºå®Ÿã«datetimeå‹ã«å¤‰æ›
    _df = agg_df.copy()
    if "æ—¥ä»˜" in _df.columns:
        _df["æ—¥ä»˜"] = pd.to_datetime(_df["æ—¥ä»˜"], errors='coerce')

    # æ•°å€¤ãŒç„¡é™å¤§ã§ãªã„ã‹ç¢ºèª
    _df = _df.replace([np.inf, -np.inf], np.nan)

    base = alt.Chart(_df).properties(title=title, height=360, width=800)

    # æ£’ã‚°ãƒ©ãƒ•1ï¼šç”Ÿç”£æ¸ˆ
    bar1 = (
        base
        .mark_bar(opacity=0.7, color='#4472C4')
        .encode(
            x=alt.X("æ—¥ä»˜:T", title="æ—¥ä»˜"),
            y=alt.Y("ç”Ÿç”£æ¸ˆ:Q", title="ç”Ÿç”£æ¸ˆ", axis=alt.Axis(orient="left")),
            tooltip=[
                alt.Tooltip("æ—¥ä»˜:T", title="æ—¥ä»˜", format="%Y/%m/%d"),
                alt.Tooltip("ç”Ÿç”£æ¸ˆ:Q", title="ç”Ÿç”£æ¸ˆ", format=".0f"),
            ],
        )
    )

    # æ£’ã‚°ãƒ©ãƒ•2ï¼šç”Ÿç”£æ™‚é–“[åˆ†]ï¼ˆé€æ˜åº¦ã‚’ä¸‹ã’ã¦é‡ã­ã‚‹ï¼‰
    bar2 = (
        base
        .mark_bar(opacity=0.5, color='#70AD47')
        .encode(
            x=alt.X("æ—¥ä»˜:T"),
            y=alt.Y("ç”Ÿç”£æ™‚é–“[åˆ†]:Q"),
            tooltip=[
                alt.Tooltip("æ—¥ä»˜:T", title="æ—¥ä»˜", format="%Y/%m/%d"),
                alt.Tooltip("ç”Ÿç”£æ™‚é–“[åˆ†]:Q", title="ç”Ÿç”£æ™‚é–“[åˆ†]", format=".0f"),
            ],
        )
    )

    # å³è»¸ï¼šå·¥æ•°ï¼ˆç§»å‹•å¹³å‡ãŒã‚ã‚Œã°ãã¡ã‚‰ã‚’å„ªå…ˆï¼‰
    y_line_field = "å·¥æ•°_MA" if "å·¥æ•°_MA" in _df.columns and _df["å·¥æ•°_MA"].notna().any() else "å·¥æ•°"
    
    # å³è»¸ç”¨ã®å·¥æ•°ãƒ©ã‚¤ãƒ³
    line = (
        base.mark_line(point=True, color="#F39C12", size=3)
        .encode(
            x=alt.X("æ—¥ä»˜:T", title=""),
            y=alt.Y(f"{y_line_field}:Q", axis=alt.Axis(title="å·¥æ•°", titleColor="#F39C12", labelColor="#F39C12", orient="right")),
            tooltip=[
                alt.Tooltip("æ—¥ä»˜:T", title="æ—¥ä»˜", format="%Y/%m/%d"),
                alt.Tooltip(f"{y_line_field}:Q", title="å·¥æ•°", format=".4f"),
            ],
        )
    )

    # å·¦è»¸ã¨å³è»¸ã‚’ç‹¬ç«‹ã•ã›ã¦åˆæˆ
    chart = (bar1 + bar2 + line).resolve_scale(y="independent")
    return chart

# -----------------------------
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šã‚ªãƒ—ã‚·ãƒ§ãƒ³
# -----------------------------
with st.sidebar:
    st.header("âš™ï¸ ã‚ªãƒ—ã‚·ãƒ§ãƒ³")

    uploaded = st.file_uploader("Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.xlsxï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"])

    st.markdown("**æ‰€è¦æ™‚é–“ã®å˜ä½**")
    time_mode = st.radio(
        "æ‰€è¦æ™‚é–“ã®æ›ç®—æ–¹æ³•",
        options=[("Excelã®æ™‚é–“ï¼ˆÃ—1440ã§åˆ†ã«æ›ç®—ï¼‰", "excel_time"), ("ã™ã§ã«åˆ†ï¼ˆæ›ç®—ãªã—ï¼‰", "minutes")],
        format_func=lambda x: x[0],
        index=0,
    )[1]

    st.markdown("**ç•°å¸¸å€¤ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆ'ç•°å¸¸å€¤'åˆ—ï¼‰**")
    abnormal_filter = st.radio(
        "ãƒ•ã‚£ãƒ«ã‚¿",
        options=[("å…¨ã¦", "all"), ("æ­£å¸¸ã®ã¿ï¼ˆ0ï¼‰", "normal"), ("ç•°å¸¸ã®ã¿ï¼ˆ1ï¼‰", "abnormal")],
        format_func=lambda x: x[0],
        horizontal=True,
        index=0,
    )[1]

    freq_options = [("æ—¥æ¬¡", "D"), ("é€±æ¬¡", "W"), ("æœˆæ¬¡", "M")]
    freq_choice = st.selectbox("é›†è¨ˆç²’åº¦", options=freq_options, format_func=lambda x: x[0], index=0)
    freq = freq_choice[1]  # ã‚¿ãƒ—ãƒ«ã®2ç•ªç›®ã®è¦ç´ ï¼ˆæ–‡å­—åˆ—ï¼‰ã‚’å–å¾—

    ma_on = st.checkbox("å·¥æ•°ã®ç§»å‹•å¹³å‡ã‚’è¡¨ç¤º", value=False)
    ma_window = st.slider("ç§»å‹•å¹³å‡ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆæ—¥æ•°æ›ç®—ï¼‰", min_value=2, max_value=28, value=7) if ma_on else None

    st.divider()
    st.caption("â€» ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œï¼ˆ0å§‹ã¾ã‚Šï¼‰ã‚’èª¿æ•´ã§ãã¾ã™ã€‚æœ€ä¸Šæ®µãŒè¦‹å‡ºã—ã§ãªã„å ´åˆã«ã”åˆ©ç”¨ãã ã•ã„ã€‚")
    cond_header_idx = st.number_input("æ¡ä»¶ã‚·ãƒ¼ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ", min_value=0, max_value=50, value=0, step=1)
    data_header_idx = st.number_input("ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆï¼ˆ39ï¼‰ã®ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ", min_value=0, max_value=50, value=0, step=1)

if not uploaded:
    st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ Excel ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.xlsxï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# -----------------------------
# Excelèª­è¾¼
# -----------------------------
with st.spinner("Excelã‚’èª­ã¿è¾¼ã¿ä¸­â€¦"):
    try:
        xl = pd.ExcelFile(uploaded, engine="openpyxl")
    except Exception as e:
        st.error(f"Excelã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.stop()

    # æ¡ä»¶ã‚·ãƒ¼ãƒˆåã®æ¨å®š
    cond_sheet_name = "æ¡ä»¶ã‚·ãƒ¼ãƒˆ" if "æ¡ä»¶ã‚·ãƒ¼ãƒˆ" in xl.sheet_names else next((s for s in xl.sheet_names if "æ¡ä»¶" in s), None)
    if not cond_sheet_name:
        st.error(f"æ¡ä»¶ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å­˜åœ¨ã™ã‚‹ã‚·ãƒ¼ãƒˆ: {xl.sheet_names}")
        st.stop()

    # ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆå
    data_sheet_name = "39" if "39" in xl.sheet_names else xl.sheet_names[0]

    try:
        cond_raw = xl.parse(cond_sheet_name, header=int(cond_header_idx))
        data_raw = xl.parse(data_sheet_name, header=int(data_header_idx))
    except Exception as e:
        st.error(f"ã‚·ãƒ¼ãƒˆã®èª­ã¿å–ã‚Šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.stop()

# æ¡ä»¶ã‚·ãƒ¼ãƒˆæ­£è¦åŒ–ï¼ˆåˆ—ä½ç½®ãƒ™ãƒ¼ã‚¹ï¼‰
cond, graph_cols = normalize_conditions_by_position(cond_raw)
gmap = build_graph_map_dynamic(cond, graph_cols)
graph_names = sorted(gmap.keys())

# ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
data = data_raw.copy()

# æ—¥ä»˜åˆ—ã®æ—¢å®šã¯ã€ŒçŠ¶æ…‹ã€
date_col_default = pick_default_date_col(data)
date_options = [c for c in DATE_CANDIDATES if c in data.columns]
if date_col_default not in date_options and date_col_default in data.columns:
    date_options.append(date_col_default)
date_col = st.selectbox(
    "æ—¥ä»˜åˆ—ã‚’é¸æŠï¼ˆæ—¢å®š=çŠ¶æ…‹ï¼‰",
    options=date_options or list(data.columns),
    index=(date_options or list(data.columns)).index(date_col_default) if (date_options or list(data.columns)) else 0
)

# æ•°å€¤åŒ–
data["ç”Ÿç”£æ¸ˆ"] = ensure_numeric(data.get("ç”Ÿç”£æ¸ˆ", pd.Series(dtype=float)), 0)
data["ç”Ÿç”£æ™‚é–“[åˆ†]"] = compute_minutes(data.get("æ‰€è¦æ™‚é–“", pd.Series(dtype=float)), time_mode)

# ç•°å¸¸å€¤ãƒ•ã‚£ãƒ«ã‚¿
if "ç•°å¸¸å€¤" in data.columns:
    if abnormal_filter == "normal":
        data = data[data["ç•°å¸¸å€¤"].fillna(0) == 0]
    elif abnormal_filter == "abnormal":
        data = data[data["ç•°å¸¸å€¤"].fillna(0) == 1]
else:
    st.warning("æ³¨æ„ï¼š'ç•°å¸¸å€¤' åˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ç•°å¸¸å€¤ãƒ•ã‚£ãƒ«ã‚¿ã¯ç„¡åŠ¹ã§ã™ã€‚")

# æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿UI
dt_series = parse_datetime_series(data.get(date_col))
if dt_series.notna().any():
    min_d, max_d = dt_series.min().date(), dt_series.max().date()
    c1, c2 = st.columns(2)
    with c1:
        start_date = st.date_input("é–‹å§‹æ—¥", value=min_d, min_value=min_d, max_value=max_d)
    with c2:
        end_date = st.date_input("çµ‚äº†æ—¥", value=max_d, min_value=min_d, max_value=max_d)
    mask = (dt_series.dt.date >= start_date) & (dt_series.dt.date <= end_date)
    data = data.loc[mask].copy()
else:
    st.warning("é¸æŠã—ãŸæ—¥ä»˜åˆ—ã‚’æ—¥æ™‚ã«è§£é‡ˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æ—¥ä»˜åˆ—ã®é¸æŠã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")

# ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
with st.expander("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­50è¡Œï¼‰", expanded=False):
    st.caption(f"ã‚·ãƒ¼ãƒˆ: {data_sheet_name} / è¡Œæ•°: {len(data)}")
    st.dataframe(data.head(50), use_container_width=True)

with st.expander("æ¡ä»¶ã‚·ãƒ¼ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­50è¡Œï¼‰", expanded=False):
    st.caption(f"ã‚·ãƒ¼ãƒˆ: {cond_sheet_name} / è¡Œæ•°: {len(cond)} / ã‚°ãƒ©ãƒ•åˆ—æ•°: {len(graph_cols)}")
    st.dataframe(cond.head(50), use_container_width=True)

# ---- ç·é›†è¨ˆï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿åˆç®—ï¼‰ ----
st.subheader("â‘  ç·é›†è¨ˆï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿åˆç®—ï¼‰")
st.caption(f"é›†è¨ˆå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(data)} ä»¶")
overall_agg = aggregate_timeseries(data, date_col=date_col, freq=freq, ma_window=(ma_window if ma_on else None))
st.caption(f"é›†è¨ˆçµæœ: {len(overall_agg)} è¡Œ")
if overall_agg.empty:
    st.warning("âš ï¸ é›†è¨ˆçµæœãŒç©ºã§ã™ã€‚æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã‚„æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.dataframe(data[[date_col, "ç”Ÿç”£æ¸ˆ", "ç”Ÿç”£æ™‚é–“[åˆ†]"]].head(10))
else:
    st.dataframe(overall_agg.head(10))
st.altair_chart(alt_dual_axis_chart(overall_agg, "ç·é›†è¨ˆ"), use_container_width=True)
st.download_button(
    "ç·é›†è¨ˆCSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
    data=overall_agg.to_csv(index=False).encode("utf-8-sig"),
    file_name="overall_aggregate.csv",
    mime="text/csv"
)

# ---- å„ã‚°ãƒ©ãƒ•åã”ã¨ ----
st.subheader("â‘¡ å„ã‚°ãƒ©ãƒ•åï¼ˆæ¡ä»¶ã‚·ãƒ¼ãƒˆ Cåˆ—ä»¥é™ï¼‰ã”ã¨ã®é›†è¨ˆ")
if not graph_names:
    st.info("æ¡ä»¶ã‚·ãƒ¼ãƒˆã«ã‚°ãƒ©ãƒ•åï¼ˆCåˆ—ä»¥é™ã®ã‚»ãƒ«å€¤ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
else:
    if "å‡ºè·å“ç•ª" not in data.columns:
        st.error("ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆã« 'å‡ºè·å“ç•ª' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ—åã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
    else:
        for gname in graph_names:
            items = sorted(gmap[gname])
            st.markdown(f"### ã‚°ãƒ©ãƒ•åï¼š**{gname}**")
            st.caption(f"å¯¾è±¡ å‡ºè·å“ç•ªï¼ˆ{len(items)}ä»¶ï¼‰ï¼š{', '.join(items[:30])}{' ...' if len(items) > 30 else ''}")

            # å‡ºè·å“ç•ªä¸€è‡´ã§æŠ½å‡ºï¼ˆå‹ãƒ–ãƒ¬å¯¾ç­–ã§æ–‡å­—åˆ—æ¯”è¼ƒï¼‰
            sub = data[data["å‡ºè·å“ç•ª"].astype(str).str.strip().isin(items)].copy()
            if sub.empty:
                st.warning("è©²å½“ãƒ‡ãƒ¼ã‚¿ãªã—")
                continue

            agg = aggregate_timeseries(sub, date_col=date_col, freq=freq, ma_window=(ma_window if ma_on else None))
            st.altair_chart(alt_dual_axis_chart(agg, f"{gname}"), use_container_width=True)
            st.download_button(
                f"{gname} ã®é›†è¨ˆCSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=agg.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"aggregate_{gname}.csv",
                mime="text/csv"
            )